# agent.py
import os
import json
from dotenv import load_dotenv
from pydantic import BaseModel, Field
from langchain_google_genai import ChatGoogleGenerativeAI
from langgraph.graph import StateGraph, START, END
from langchain_core.messages import HumanMessage, SystemMessage

# from tools import connect_onedrive, fetch_files_from_onedrive

load_dotenv()

# === çŠ¶æ…‹ç®¡ç† ===
class AgentState(BaseModel):
    question: str = Field(default="ã“ã‚“ã«ã¡ã¯")
    quantity_file_list: list | None = None
    quality_file_list: list | None = None
    selected_files: list | None = None
    file_contents: dict | None = None
    answer: str | None = None
    access_token: str

# === LLMè¨­å®š ===
llm = ChatGoogleGenerativeAI(
    model=os.getenv("GEMINI_MODEL"),
    temperature=0,
    transport="rest"
)

# â‘  OneDriveã®ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—
def list_files_node(state: AgentState):
    # state.file_list = connect_onedrive.run("Test")
    return state

# â‘¡ LLMã§ã€Œä½¿ã†ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã©ã‚Œï¼Ÿã€ã‚’åˆ¤æ–­
def analyze_node(state: AgentState):
    prompt = f"""
    ãƒ¦ãƒ¼ã‚¶ãƒ¼: {state.question}
    ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§: {state.file_list}

    ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã‚’è¦‹ãŸãŒã£ã¦ã„ã‚‹å ´åˆã€
    å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«åã ã‘ã‚’ JSON ã§è¿”ã—ã¦ãã ã•ã„:

    ä¾‹:
    {{"files": ["finance.csv"]}}

    èª¬æ˜æ–‡ã¯ç¦æ­¢ã€‚JSONå½¢å¼ã®ã¿å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
    """
    res = llm.invoke([HumanMessage(content=prompt)]).content
    print("LLMå¿œç­”:", res)

    try:
        parsed = json.loads(res)
        state.selected_files = parsed.get("files", [])
    except:
        state.selected_files = []
    return state

# â‘¢ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®Ÿéš›ã«å–å¾—
def fetch_files_node(state: AgentState):
    if state.selected_files:
        # state.file_contents = fetch_files_from_onedrive(state.selected_files, "Test")
        state.answer = f"âœ… å–å¾—ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«: {state.selected_files}"
    else:
        state.answer = "ğŸ“‚ å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã¯ãªã„ã¨åˆ¤æ–­ã—ã¾ã—ãŸ"
    return state

# â‘£ å¿œç­”
def respond_node(state: AgentState):
    return state

# === ã‚°ãƒ©ãƒ•æ§‹ç¯‰ ===
def build_graph():
    graph = StateGraph(AgentState)
    graph.add_node("list_files", list_files_node)
    graph.add_node("analyze", analyze_node)
    graph.add_node("fetch_files", fetch_files_node)
    graph.add_node("respond", respond_node)

    graph.add_edge(START, "list_files")
    graph.add_edge("list_files", "analyze")
    graph.add_edge("analyze", "fetch_files")
    graph.add_edge("fetch_files", "respond")
    graph.add_edge("respond", END)

    return graph.compile()

if __name__ == "__main__":
    # app = build_graph()
    # result = app.invoke(AgentState(question="Testãƒ•ã‚©ãƒ«ãƒ€ã®finance.csvã‚’è¦‹ã›ã¦"))

    # print("ğŸ“Œ å›ç­”:", result.get("answer"))
    # print("ğŸ¯ é¸æŠã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«:", result.get("selected_files"))
    # print("ğŸ“‚ å–å¾—ã—ãŸå†…å®¹:", result.get("file_contents"))
    files = ["finance.csv", "tecnology.csv"]
    system_prompt = f"""ã‚ãªãŸã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¿œã˜ã¦é©åˆ‡ãªãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚’é¸å¯¾ã—ã¦è¿”ã™AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚é¸æŠã§ãã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã¯æ¬¡ã®ã‚‚ã®ã§ã™ã€‚{files}
    ã¾ãŸã€è¿”ç­”ã™ã‚‹å†…å®¹ã¯ãƒ•ã‚¡ã‚¤ãƒ«åã‚’æ ¼ç´ã—ãŸãƒªã‚¹ãƒˆå½¢å¼ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ã¿ã¨ã—ã¦ãã ã•ã„ã€‚
    ä¾‹ï¼šãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®è³ªå•
    ã€Œãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ã«é–¢ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ã—ã¦ãã ã•ã„ã€‚ã€
    ã‚ãªãŸã®å›ç­”
    ['tecnology.csv']
    """
    user_prompt = "é‡‘èã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ã—ã¦ãã ã•ã„ã€‚"
    messages = [SystemMessage(content=system_prompt),
              HumanMessage(content=user_prompt)]
    result = llm.invoke(messages)
    print(result)